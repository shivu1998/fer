{"filter":false,"title":"detectfaces.py","tooltip":"/routes/detectfaces.py","undoManager":{"mark":34,"position":34,"stack":[[{"start":{"row":0,"column":0},"end":{"row":93,"column":0},"action":"insert","lines":["# USAGE","# python detect_faces.py --image rooster.jpg --prototxt deploy.prototxt.txt --model res10_300x300_ssd_iter_140000.caffemodel","","# import the necessary packages","import numpy as np","import argparse","import cv2","import glob","import os","from datetime import datetime","di=\"C:\\\\Users\\shivu\\Anaconda2\\Desktop\\\\mile2\\\\\"","os.chdir(\"C:\\\\Users\\shivu\\Anaconda2\\Desktop\\\\mile2\\\\\")","","# construct the argument parse and parse the arguments","'''","ap = argparse.ArgumentParser()","ap.add_argument(\"-i\", \"--image\", required=True,","\thelp=\"path to input image\")","ap.add_argument(\"-p\", \"--prototxt\", required=True,","\thelp=\"path to Caffe 'deploy' prototxt file\")","ap.add_argument(\"-m\", \"--model\", required=True,","\thelp=\"path to Caffe pre-trained model\")","ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,","\thelp=\"minimum probability to filter weak detections\")","args = vars(ap.parse_args())","print(args)'''","{'image': 'rooster.jpg', 'prototxt': 'deploy.prototxt.txt', 'model': 'res10_300x300_ssd_iter_140000.caffemodel', 'confidence': 0.5}","# load our serialized model from disk","#print(\"[INFO] loading model...\")","prototxt='C:\\\\Users\\shivu\\\\bopro\\deeplearning\\pyimagesearch\\deep-learning-face-detection\\deep-learning-face-detection\\deploy.prototxt.txt'","model='C:\\\\Users\\shivu\\\\bopro\\deeplearning\\pyimagesearch\\deep-learning-face-detection\\deep-learning-face-detection\\\\res10_300x300_ssd_iter_140000.caffemodel'","#net = cv2.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])","net=cv2.dnn.readNetFromCaffe(prototxt,model)","","# load the input image and construct an input blob for the image","# by resizing to a fixed 300x300 pixels and then normalizing it","#image = cv2.imread(args[\"image\"])","def facechop(images):","        count=0","        for img in images:","                #print(len(images))","                image=cv2.imread(img)","                if image is not None:","                        (h, w) = image.shape[:2]","                        blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0,","                                (300, 300), (104.0, 177.0, 123.0))","","                        # pass the blob through the network and obtain the detections and","                        # predictions","                        #print(\"[INFO] computing object detections...\")","                        net.setInput(blob)","                        detections = net.forward()","","                        # loop over the detections","                        for i in range(0, detections.shape[2]):","                                # extract the confidence (i.e., probability) associated with the","                                # prediction","                                confidence = detections[0, 0, i, 2]","","                                # filter out weak detections by ensuring the `confidence` is","                                # greater than the minimum confidence","                                if confidence > 0.6 :","                                        # compute the (x, y)-coordinates of the bounding box for the","                                        # object","                                        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])","                                        (startX, startY, endX, endY) = box.astype(\"int\")","                         ","                                        # draw the bounding box of the face along with the associated","                                        # probability","                                        #text = \"{:.2f}%\".format(confidence * 100)","                                        y = startY - 10 if startY - 10 > 10 else startY + 10","                                        cv2.rectangle(image, (startX, startY), (endX, endY),","                                                (255, 255, 255))","                                        file=image[startY:endY,startX:endX]","                                        #cv2.putText(image, text, (startX, y),","                                        #        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)","                                        face_file=di+str(datetime.now().microsecond)+str(count)+\".jpg\"","                                        #print(face_file)","                                        cv2.imwrite(face_file,file)","                                count+=1","                                       ","","                        # show the output image","                        #cv2.imshow(\"Output\", image)","                        #cv2.waitKey(0)","                else:","                        print(img)","","if __name__ == \"__main__\":","        source_dir=\"C:\\\\Users\\\\shivu\\\\Downloads\\\\python notes\\\\pythonpics\\\\downloads\\\\afraid human faces\\\\*\"","        #source_dir=\"C:\\\\Users\\\\shivu\\\\Anaconda2\\\\Desktop\\\\faces\\\\surprised\\\\*.JPG\"","        images=glob.glob(source_dir)","        facechop(images)",""],"id":1}],[{"start":{"row":9,"column":29},"end":{"row":10,"column":0},"action":"insert","lines":["",""],"id":2}],[{"start":{"row":10,"column":0},"end":{"row":10,"column":9},"action":"insert","lines":["/captured"],"id":3}],[{"start":{"row":10,"column":8},"end":{"row":10,"column":9},"action":"remove","lines":["d"],"id":4},{"start":{"row":10,"column":7},"end":{"row":10,"column":8},"action":"remove","lines":["e"]},{"start":{"row":10,"column":6},"end":{"row":10,"column":7},"action":"remove","lines":["r"]},{"start":{"row":10,"column":5},"end":{"row":10,"column":6},"action":"remove","lines":["u"]},{"start":{"row":10,"column":4},"end":{"row":10,"column":5},"action":"remove","lines":["t"]},{"start":{"row":10,"column":3},"end":{"row":10,"column":4},"action":"remove","lines":["p"]},{"start":{"row":10,"column":2},"end":{"row":10,"column":3},"action":"remove","lines":["a"]},{"start":{"row":10,"column":1},"end":{"row":10,"column":2},"action":"remove","lines":["c"]},{"start":{"row":10,"column":0},"end":{"row":10,"column":1},"action":"remove","lines":["/"]}],[{"start":{"row":11,"column":4},"end":{"row":11,"column":46},"action":"remove","lines":["C:\\\\Users\\shivu\\Anaconda2\\Desktop\\\\mile2\\\\"],"id":5}],[{"start":{"row":11,"column":4},"end":{"row":11,"column":13},"action":"insert","lines":["/captured"],"id":6}],[{"start":{"row":11,"column":13},"end":{"row":11,"column":14},"action":"insert","lines":["/"],"id":7}],[{"start":{"row":12,"column":10},"end":{"row":12,"column":52},"action":"remove","lines":["C:\\\\Users\\shivu\\Anaconda2\\Desktop\\\\mile2\\\\"],"id":8}],[{"start":{"row":12,"column":10},"end":{"row":12,"column":19},"action":"insert","lines":["/captured"],"id":9}],[{"start":{"row":12,"column":19},"end":{"row":12,"column":20},"action":"insert","lines":["/"],"id":10}],[{"start":{"row":11,"column":4},"end":{"row":11,"column":5},"action":"insert","lines":["."],"id":11},{"start":{"row":11,"column":5},"end":{"row":11,"column":6},"action":"insert","lines":["."]}],[{"start":{"row":12,"column":10},"end":{"row":12,"column":11},"action":"insert","lines":["."],"id":12},{"start":{"row":12,"column":11},"end":{"row":12,"column":12},"action":"insert","lines":["."]}],[{"start":{"row":29,"column":33},"end":{"row":30,"column":0},"action":"insert","lines":["",""],"id":13}],[{"start":{"row":30,"column":0},"end":{"row":30,"column":41},"action":"insert","lines":["/res10_300x300_ssd_iter_140000.caffemodel"],"id":14}],[{"start":{"row":30,"column":0},"end":{"row":30,"column":41},"action":"remove","lines":["/res10_300x300_ssd_iter_140000.caffemodel"],"id":15}],[{"start":{"row":32,"column":7},"end":{"row":32,"column":156},"action":"remove","lines":["C:\\\\Users\\shivu\\\\bopro\\deeplearning\\pyimagesearch\\deep-learning-face-detection\\deep-learning-face-detection\\\\res10_300x300_ssd_iter_140000.caffemodel"],"id":16}],[{"start":{"row":32,"column":7},"end":{"row":32,"column":48},"action":"insert","lines":["/res10_300x300_ssd_iter_140000.caffemodel"],"id":17}],[{"start":{"row":32,"column":7},"end":{"row":32,"column":8},"action":"insert","lines":["."],"id":18},{"start":{"row":32,"column":8},"end":{"row":32,"column":9},"action":"insert","lines":["."]}],[{"start":{"row":31,"column":10},"end":{"row":31,"column":137},"action":"remove","lines":["C:\\\\Users\\shivu\\\\bopro\\deeplearning\\pyimagesearch\\deep-learning-face-detection\\deep-learning-face-detection\\deploy.prototxt.txt"],"id":19}],[{"start":{"row":31,"column":10},"end":{"row":31,"column":30},"action":"insert","lines":["/deploy.prototxt.txt"],"id":20}],[{"start":{"row":31,"column":10},"end":{"row":31,"column":11},"action":"insert","lines":["."],"id":21},{"start":{"row":31,"column":11},"end":{"row":31,"column":12},"action":"insert","lines":["."]}],[{"start":{"row":0,"column":0},"end":{"row":0,"column":2},"action":"insert","lines":["# "],"id":22},{"start":{"row":1,"column":0},"end":{"row":1,"column":2},"action":"insert","lines":["# "]},{"start":{"row":3,"column":0},"end":{"row":3,"column":2},"action":"insert","lines":["# "]},{"start":{"row":4,"column":0},"end":{"row":4,"column":2},"action":"insert","lines":["# "]},{"start":{"row":5,"column":0},"end":{"row":5,"column":2},"action":"insert","lines":["# "]},{"start":{"row":6,"column":0},"end":{"row":6,"column":2},"action":"insert","lines":["# "]},{"start":{"row":7,"column":0},"end":{"row":7,"column":2},"action":"insert","lines":["# "]},{"start":{"row":8,"column":0},"end":{"row":8,"column":2},"action":"insert","lines":["# "]},{"start":{"row":9,"column":0},"end":{"row":9,"column":2},"action":"insert","lines":["# "]},{"start":{"row":11,"column":0},"end":{"row":11,"column":2},"action":"insert","lines":["# "]},{"start":{"row":12,"column":0},"end":{"row":12,"column":2},"action":"insert","lines":["# "]},{"start":{"row":14,"column":0},"end":{"row":14,"column":2},"action":"insert","lines":["# "]},{"start":{"row":15,"column":0},"end":{"row":15,"column":2},"action":"insert","lines":["# "]},{"start":{"row":16,"column":0},"end":{"row":16,"column":2},"action":"insert","lines":["# "]},{"start":{"row":17,"column":0},"end":{"row":17,"column":2},"action":"insert","lines":["# "]},{"start":{"row":18,"column":0},"end":{"row":18,"column":2},"action":"insert","lines":["# "]},{"start":{"row":19,"column":0},"end":{"row":19,"column":2},"action":"insert","lines":["# "]},{"start":{"row":20,"column":0},"end":{"row":20,"column":2},"action":"insert","lines":["# "]},{"start":{"row":21,"column":0},"end":{"row":21,"column":2},"action":"insert","lines":["# "]},{"start":{"row":22,"column":0},"end":{"row":22,"column":2},"action":"insert","lines":["# "]},{"start":{"row":23,"column":0},"end":{"row":23,"column":2},"action":"insert","lines":["# "]},{"start":{"row":24,"column":0},"end":{"row":24,"column":2},"action":"insert","lines":["# "]},{"start":{"row":25,"column":0},"end":{"row":25,"column":2},"action":"insert","lines":["# "]},{"start":{"row":26,"column":0},"end":{"row":26,"column":2},"action":"insert","lines":["# "]},{"start":{"row":27,"column":0},"end":{"row":27,"column":2},"action":"insert","lines":["# "]},{"start":{"row":28,"column":0},"end":{"row":28,"column":2},"action":"insert","lines":["# "]},{"start":{"row":29,"column":0},"end":{"row":29,"column":2},"action":"insert","lines":["# "]},{"start":{"row":31,"column":0},"end":{"row":31,"column":2},"action":"insert","lines":["# "]},{"start":{"row":32,"column":0},"end":{"row":32,"column":2},"action":"insert","lines":["# "]},{"start":{"row":33,"column":0},"end":{"row":33,"column":2},"action":"insert","lines":["# "]},{"start":{"row":34,"column":0},"end":{"row":34,"column":2},"action":"insert","lines":["# "]},{"start":{"row":36,"column":0},"end":{"row":36,"column":2},"action":"insert","lines":["# "]},{"start":{"row":37,"column":0},"end":{"row":37,"column":2},"action":"insert","lines":["# "]},{"start":{"row":38,"column":0},"end":{"row":38,"column":2},"action":"insert","lines":["# "]},{"start":{"row":39,"column":0},"end":{"row":39,"column":2},"action":"insert","lines":["# "]},{"start":{"row":40,"column":0},"end":{"row":40,"column":2},"action":"insert","lines":["# "]},{"start":{"row":41,"column":0},"end":{"row":41,"column":2},"action":"insert","lines":["# "]},{"start":{"row":42,"column":0},"end":{"row":42,"column":2},"action":"insert","lines":["# "]},{"start":{"row":43,"column":0},"end":{"row":43,"column":2},"action":"insert","lines":["# "]},{"start":{"row":44,"column":0},"end":{"row":44,"column":2},"action":"insert","lines":["# "]},{"start":{"row":45,"column":0},"end":{"row":45,"column":2},"action":"insert","lines":["# "]},{"start":{"row":46,"column":0},"end":{"row":46,"column":2},"action":"insert","lines":["# "]},{"start":{"row":47,"column":0},"end":{"row":47,"column":2},"action":"insert","lines":["# "]},{"start":{"row":49,"column":0},"end":{"row":49,"column":2},"action":"insert","lines":["# "]},{"start":{"row":50,"column":0},"end":{"row":50,"column":2},"action":"insert","lines":["# "]},{"start":{"row":51,"column":0},"end":{"row":51,"column":2},"action":"insert","lines":["# "]},{"start":{"row":52,"column":0},"end":{"row":52,"column":2},"action":"insert","lines":["# "]},{"start":{"row":53,"column":0},"end":{"row":53,"column":2},"action":"insert","lines":["# "]},{"start":{"row":55,"column":0},"end":{"row":55,"column":2},"action":"insert","lines":["# "]},{"start":{"row":56,"column":0},"end":{"row":56,"column":2},"action":"insert","lines":["# "]},{"start":{"row":57,"column":0},"end":{"row":57,"column":2},"action":"insert","lines":["# "]},{"start":{"row":58,"column":0},"end":{"row":58,"column":2},"action":"insert","lines":["# "]},{"start":{"row":59,"column":0},"end":{"row":59,"column":2},"action":"insert","lines":["# "]},{"start":{"row":61,"column":0},"end":{"row":61,"column":2},"action":"insert","lines":["# "]},{"start":{"row":62,"column":0},"end":{"row":62,"column":2},"action":"insert","lines":["# "]},{"start":{"row":63,"column":0},"end":{"row":63,"column":2},"action":"insert","lines":["# "]},{"start":{"row":64,"column":0},"end":{"row":64,"column":2},"action":"insert","lines":["# "]},{"start":{"row":65,"column":0},"end":{"row":65,"column":2},"action":"insert","lines":["# "]},{"start":{"row":66,"column":0},"end":{"row":66,"column":2},"action":"insert","lines":["# "]},{"start":{"row":67,"column":0},"end":{"row":67,"column":2},"action":"insert","lines":["# "]},{"start":{"row":69,"column":0},"end":{"row":69,"column":2},"action":"insert","lines":["# "]},{"start":{"row":70,"column":0},"end":{"row":70,"column":2},"action":"insert","lines":["# "]},{"start":{"row":71,"column":0},"end":{"row":71,"column":2},"action":"insert","lines":["# "]},{"start":{"row":72,"column":0},"end":{"row":72,"column":2},"action":"insert","lines":["# "]},{"start":{"row":73,"column":0},"end":{"row":73,"column":2},"action":"insert","lines":["# "]},{"start":{"row":74,"column":0},"end":{"row":74,"column":2},"action":"insert","lines":["# "]},{"start":{"row":75,"column":0},"end":{"row":75,"column":2},"action":"insert","lines":["# "]},{"start":{"row":76,"column":0},"end":{"row":76,"column":2},"action":"insert","lines":["# "]},{"start":{"row":77,"column":0},"end":{"row":77,"column":2},"action":"insert","lines":["# "]},{"start":{"row":78,"column":0},"end":{"row":78,"column":2},"action":"insert","lines":["# "]},{"start":{"row":79,"column":0},"end":{"row":79,"column":2},"action":"insert","lines":["# "]},{"start":{"row":80,"column":0},"end":{"row":80,"column":2},"action":"insert","lines":["# "]},{"start":{"row":81,"column":0},"end":{"row":81,"column":2},"action":"insert","lines":["# "]},{"start":{"row":84,"column":0},"end":{"row":84,"column":2},"action":"insert","lines":["# "]},{"start":{"row":85,"column":0},"end":{"row":85,"column":2},"action":"insert","lines":["# "]},{"start":{"row":86,"column":0},"end":{"row":86,"column":2},"action":"insert","lines":["# "]},{"start":{"row":87,"column":0},"end":{"row":87,"column":2},"action":"insert","lines":["# "]},{"start":{"row":88,"column":0},"end":{"row":88,"column":2},"action":"insert","lines":["# "]},{"start":{"row":90,"column":0},"end":{"row":90,"column":2},"action":"insert","lines":["# "]},{"start":{"row":91,"column":0},"end":{"row":91,"column":2},"action":"insert","lines":["# "]},{"start":{"row":92,"column":0},"end":{"row":92,"column":2},"action":"insert","lines":["# "]},{"start":{"row":93,"column":0},"end":{"row":93,"column":2},"action":"insert","lines":["# "]},{"start":{"row":94,"column":0},"end":{"row":94,"column":2},"action":"insert","lines":["# "]}],[{"start":{"row":95,"column":0},"end":{"row":193,"column":0},"action":"insert","lines":["# USAGE","# python detect_faces_video.py --prototxt deploy.prototxt.txt --model res10_300x300_ssd_iter_140000.caffemodel","","# import the necessary packages","from imutils.video import VideoStream","import numpy as np","import argparse","import imutils","import time","import cv2","import os","from datetime import datetime","di=\"C:\\\\Users\\shivu\\Anaconda2\\Desktop\\\\mile3\\\\\"","os.chdir(\"C:\\\\Users\\shivu\\Anaconda2\\Desktop\\\\mile3\\\\\")","# construct the argument parse and parse the arguments","'''","ap = argparse.ArgumentParser()","ap.add_argument(\"-i\", \"--image\", required=True,","    help=\"path to input image\")","ap.add_argument(\"-p\", \"--prototxt\", required=True,","    help=\"path to Caffe 'deploy' prototxt file\")","ap.add_argument(\"-m\", \"--model\", required=True,","    help=\"path to Caffe pre-trained model\")","ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,","    help=\"minimum probability to filter weak detections\")","args = vars(ap.parse_args())","print(args)'''","{'image': 'rooster.jpg', 'prototxt': 'deploy.prototxt.txt', 'model': 'res10_300x300_ssd_iter_140000.caffemodel', 'confidence': 0.5}","# load our serialized model from disk","#print(\"[INFO] loading model...\")","prototxt='C:\\\\Users\\shivu\\\\bopro\\deeplearning\\pyimagesearch\\deep-learning-face-detection\\deep-learning-face-detection\\deploy.prototxt.txt'","model='C:\\\\Users\\shivu\\\\bopro\\deeplearning\\pyimagesearch\\deep-learning-face-detection\\deep-learning-face-detection\\\\res10_300x300_ssd_iter_140000.caffemodel'","net = cv2.dnn.readNetFromCaffe(prototxt,model)","","# initialize the video stream and allow the cammera sensor to warmup","print(\"[INFO] starting video stream...\")","vs = VideoStream(src=0).start()","time.sleep(1.0)","","# loop over the frames from the video stream","while True:","    # grab the frame from the threaded video stream and resize it","    # to have a maximum width of 400 pixels","    frame = vs.read()","    frame = imutils.resize(frame, width=400)"," ","    # grab the frame dimensions and convert it to a blob","    (h, w) = frame.shape[:2]","    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,","        (300, 300), (104.0, 177.0, 123.0))"," ","    # pass the blob through the network and obtain the detections and","    # predictions","    net.setInput(blob)","    detections = net.forward()","","    # loop over the detections","    for i in range(0, detections.shape[2]):","        # extract the confidence (i.e., probability) associated with the","        # prediction","        confidence = detections[0, 0, i, 2]","","        # filter out weak detections by ensuring the `confidence` is","        # greater than the minimum confidence","        if confidence < 0.5:","            continue","","        # compute the (x, y)-coordinates of the bounding box for the","        # object","        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])","        (startX, startY, endX, endY) = box.astype(\"int\")"," ","        # draw the bounding box of the face along with the associated","        # probability","        text = \"{:.2f}%\".format(confidence * 100)","        y = startY - 10 if startY - 10 > 10 else startY + 10","        file=frame[startY:endY,startX:endX]","        cv2.rectangle(frame, (startX, startY), (endX, endY),","            (255, 255, 255))","##        cv2.putText(frame, text, (startX, y),","##            cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,255, 255))","        file_name=di+str(datetime.now().microsecond)+\".jpg\"","        print(file_name)","        cv2.imwrite(file_name,file)","","    # show the output frame","    cv2.imshow(\"Frame\", frame)","    key = cv2.waitKey(3) & 0xFF"," ","    # if the `q` key was pressed, break from the loop","    if key == ord(\"q\"):","                VideoStream(src=0).stop()","                break","        ","","# do a bit of cleanup","cv2.destroyAllWindows()","vs.stop()",""],"id":23}],[{"start":{"row":122,"column":0},"end":{"row":122,"column":1},"action":"insert","lines":["#"],"id":24}],[{"start":{"row":125,"column":0},"end":{"row":126,"column":157},"action":"remove","lines":["prototxt='C:\\\\Users\\shivu\\\\bopro\\deeplearning\\pyimagesearch\\deep-learning-face-detection\\deep-learning-face-detection\\deploy.prototxt.txt'","model='C:\\\\Users\\shivu\\\\bopro\\deeplearning\\pyimagesearch\\deep-learning-face-detection\\deep-learning-face-detection\\\\res10_300x300_ssd_iter_140000.caffemodel'"],"id":25},{"start":{"row":125,"column":0},"end":{"row":126,"column":53},"action":"insert","lines":["prototxt='../deploy.prototxt.txt'","# model='../res10_300x300_ssd_iter_140000.caffemodel'"]}],[{"start":{"row":126,"column":1},"end":{"row":126,"column":2},"action":"remove","lines":[" "],"id":26},{"start":{"row":126,"column":0},"end":{"row":126,"column":1},"action":"remove","lines":["#"]}],[{"start":{"row":0,"column":0},"end":{"row":99,"column":0},"action":"remove","lines":["# # USAGE","# # python detect_faces.py --image rooster.jpg --prototxt deploy.prototxt.txt --model res10_300x300_ssd_iter_140000.caffemodel","","# # import the necessary packages","# import numpy as np","# import argparse","# import cv2","# import glob","# import os","# from datetime import datetime","","# di=\"../captured/\"","# os.chdir(\"../captured/\")","","# # construct the argument parse and parse the arguments","# '''","# ap = argparse.ArgumentParser()","# ap.add_argument(\"-i\", \"--image\", required=True,","# \thelp=\"path to input image\")","# ap.add_argument(\"-p\", \"--prototxt\", required=True,","# \thelp=\"path to Caffe 'deploy' prototxt file\")","# ap.add_argument(\"-m\", \"--model\", required=True,","# \thelp=\"path to Caffe pre-trained model\")","# ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,","# \thelp=\"minimum probability to filter weak detections\")","# args = vars(ap.parse_args())","# print(args)'''","# {'image': 'rooster.jpg', 'prototxt': 'deploy.prototxt.txt', 'model': 'res10_300x300_ssd_iter_140000.caffemodel', 'confidence': 0.5}","# # load our serialized model from disk","# #print(\"[INFO] loading model...\")","","# prototxt='../deploy.prototxt.txt'","# model='../res10_300x300_ssd_iter_140000.caffemodel'","# #net = cv2.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])","# net=cv2.dnn.readNetFromCaffe(prototxt,model)","","# # load the input image and construct an input blob for the image","# # by resizing to a fixed 300x300 pixels and then normalizing it","# #image = cv2.imread(args[\"image\"])","# def facechop(images):","#         count=0","#         for img in images:","#                 #print(len(images))","#                 image=cv2.imread(img)","#                 if image is not None:","#                         (h, w) = image.shape[:2]","#                         blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0,","#                                 (300, 300), (104.0, 177.0, 123.0))","","#                         # pass the blob through the network and obtain the detections and","#                         # predictions","#                         #print(\"[INFO] computing object detections...\")","#                         net.setInput(blob)","#                         detections = net.forward()","","#                         # loop over the detections","#                         for i in range(0, detections.shape[2]):","#                                 # extract the confidence (i.e., probability) associated with the","#                                 # prediction","#                                 confidence = detections[0, 0, i, 2]","","#                                 # filter out weak detections by ensuring the `confidence` is","#                                 # greater than the minimum confidence","#                                 if confidence > 0.6 :","#                                         # compute the (x, y)-coordinates of the bounding box for the","#                                         # object","#                                         box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])","#                                         (startX, startY, endX, endY) = box.astype(\"int\")","                         ","#                                         # draw the bounding box of the face along with the associated","#                                         # probability","#                                         #text = \"{:.2f}%\".format(confidence * 100)","#                                         y = startY - 10 if startY - 10 > 10 else startY + 10","#                                         cv2.rectangle(image, (startX, startY), (endX, endY),","#                                                 (255, 255, 255))","#                                         file=image[startY:endY,startX:endX]","#                                         #cv2.putText(image, text, (startX, y),","#                                         #        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)","#                                         face_file=di+str(datetime.now().microsecond)+str(count)+\".jpg\"","#                                         #print(face_file)","#                                         cv2.imwrite(face_file,file)","#                                 count+=1","                                       ","","#                         # show the output image","#                         #cv2.imshow(\"Output\", image)","#                         #cv2.waitKey(0)","#                 else:","#                         print(img)","","# if __name__ == \"__main__\":","#         source_dir=\"C:\\\\Users\\\\shivu\\\\Downloads\\\\python notes\\\\pythonpics\\\\downloads\\\\afraid human faces\\\\*\"","#         #source_dir=\"C:\\\\Users\\\\shivu\\\\Anaconda2\\\\Desktop\\\\faces\\\\surprised\\\\*.JPG\"","#         images=glob.glob(source_dir)","#         facechop(images)","# USAGE","# python detect_faces_video.py --prototxt deploy.prototxt.txt --model res10_300x300_ssd_iter_140000.caffemodel","","# import the necessary packages",""],"id":29}],[{"start":{"row":8,"column":0},"end":{"row":9,"column":54},"action":"remove","lines":["di=\"C:\\\\Users\\shivu\\Anaconda2\\Desktop\\\\mile3\\\\\"","os.chdir(\"C:\\\\Users\\shivu\\Anaconda2\\Desktop\\\\mile3\\\\\")"],"id":30},{"start":{"row":8,"column":0},"end":{"row":10,"column":0},"action":"insert","lines":["# di=\"../captured/\"","# os.chdir(\"../captured/\")",""]}],[{"start":{"row":9,"column":0},"end":{"row":9,"column":1},"action":"remove","lines":["#"],"id":31}],[{"start":{"row":8,"column":0},"end":{"row":8,"column":1},"action":"remove","lines":["#"],"id":32}],[{"start":{"row":8,"column":0},"end":{"row":8,"column":1},"action":"remove","lines":[" "],"id":33}],[{"start":{"row":9,"column":0},"end":{"row":9,"column":1},"action":"remove","lines":[" "],"id":34}],[{"start":{"row":12,"column":0},"end":{"row":23,"column":14},"action":"remove","lines":["'''","ap = argparse.ArgumentParser()","ap.add_argument(\"-i\", \"--image\", required=True,","    help=\"path to input image\")","ap.add_argument(\"-p\", \"--prototxt\", required=True,","    help=\"path to Caffe 'deploy' prototxt file\")","ap.add_argument(\"-m\", \"--model\", required=True,","    help=\"path to Caffe pre-trained model\")","ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,","    help=\"minimum probability to filter weak detections\")","args = vars(ap.parse_args())","print(args)'''"],"id":35}],[{"start":{"row":10,"column":0},"end":{"row":15,"column":33},"action":"remove","lines":["","# construct the argument parse and parse the arguments","","#{'image': 'rooster.jpg', 'prototxt': 'deploy.prototxt.txt', 'model': 'res10_300x300_ssd_iter_140000.caffemodel', 'confidence': 0.5}","# load our serialized model from disk","#print(\"[INFO] loading model...\")"],"id":36}],[{"start":{"row":2,"column":14},"end":{"row":2,"column":15},"action":"remove","lines":["e"],"id":37},{"start":{"row":2,"column":13},"end":{"row":2,"column":14},"action":"remove","lines":["s"]},{"start":{"row":2,"column":12},"end":{"row":2,"column":13},"action":"remove","lines":["r"]},{"start":{"row":2,"column":11},"end":{"row":2,"column":12},"action":"remove","lines":["a"]},{"start":{"row":2,"column":10},"end":{"row":2,"column":11},"action":"remove","lines":["p"]},{"start":{"row":2,"column":9},"end":{"row":2,"column":10},"action":"remove","lines":["g"]},{"start":{"row":2,"column":8},"end":{"row":2,"column":9},"action":"remove","lines":["r"]},{"start":{"row":2,"column":7},"end":{"row":2,"column":8},"action":"remove","lines":["a"]},{"start":{"row":2,"column":6},"end":{"row":2,"column":7},"action":"remove","lines":[" "]},{"start":{"row":2,"column":5},"end":{"row":2,"column":6},"action":"remove","lines":["t"]},{"start":{"row":2,"column":4},"end":{"row":2,"column":5},"action":"remove","lines":["r"]},{"start":{"row":2,"column":3},"end":{"row":2,"column":4},"action":"remove","lines":["o"]},{"start":{"row":2,"column":2},"end":{"row":2,"column":3},"action":"remove","lines":["p"]},{"start":{"row":2,"column":1},"end":{"row":2,"column":2},"action":"remove","lines":["m"]},{"start":{"row":2,"column":0},"end":{"row":2,"column":1},"action":"remove","lines":["i"]},{"start":{"row":1,"column":18},"end":{"row":2,"column":0},"action":"remove","lines":["",""]}]]},"ace":{"folds":[],"scrolltop":0,"scrollleft":0,"selection":{"start":{"row":0,"column":0},"end":{"row":0,"column":37},"isBackwards":true},"options":{"guessTabSize":true,"useWrapMode":false,"wrapToView":true},"firstLineState":0},"timestamp":1553445000853,"hash":"dabae79abb0f6d2b3dca4552af4ccc5aee6446ea"}